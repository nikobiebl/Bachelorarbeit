## Introduction

This is the official repository to my **Bachelor thesis** with the following title: 

**"Vergleich von Interaktionsstrategien für multiagentenbasierte Bewertungssysteme im Rahmen von LLMOps"**

English translation: 

**"Comparison of Interaction Strategies for Multi-Agent-based Evaluation Systems in the Context of LLMOps"**

## Used Framework for Multi-Agent-Systems

### AutoGen

  **From:**
  
  Wu, Qingyun et al. 2024. »AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation«, in Proceedings of the LLM Agents Workshop at the International Conference on Learning Representations.

  **GitHub:** https://github.com/microsoft/autogen

  **License:** [MIT License](https://github.com/microsoft/autogen/blob/main/LICENSE)

## Used Benchmarks for Evaluation

### JudgeBench

  **From:**
  
  Tan, Sijun et al. 2025. »JudgeBench: A Benchmark for Evaluating LLM-Based Judges«, in Proceedings Of The Thirteenth International Conference on Learning Representations.
  
  **Accessed through:**
  
  https://huggingface.co/datasets/ScalerLab/JudgeBench

  **GitHub:** https://github.com/ScalerLab/JudgeBench

  **License:** [MIT License](https://choosealicense.com/licenses/mit/) (no LICENSE file in the original GitHub repo, but MIT is listed at the top right on the Hugging Face dataset page)

### SummEval

  **From:**
  
  Fabbri, Alexander R. et al. 2021. »SummEval: Re-evaluating Summarization Evaluation«, in Transactions of the Association for Computational Linguistics 9, S. 391–409.
  
  **Accessed through:**
  
  https://huggingface.co/datasets/mteb/summeval

  **GitHub:** https://github.com/Yale-LILY/SummEval

  **License:** [MIT License](https://github.com/Yale-LILY/SummEval/blob/master/LICENSE)
  
---
> This repository is part of an academic research project submitted as a Bachelor's thesis at DHBW Stuttgart. All external resources are used strictly for academic and non-commercial purposes.
